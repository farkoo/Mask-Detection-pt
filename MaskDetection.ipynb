{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b520c9a",
   "metadata": {
    "id": "9b520c9a"
   },
   "source": [
    "<div dir=rtl>\n",
    "    \n",
    "# تکلیف دوم عملی\n",
    "\n",
    "## فرزانه کوهستانی - 40115824\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1MpRL2F8h2JX",
   "metadata": {
    "id": "1MpRL2F8h2JX"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7784\\1408506528.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a5890d1",
   "metadata": {
    "id": "2a5890d1"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7784\\2988752608.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2_imshow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import walk\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "import time \n",
    "import tqdm\n",
    "from tqdm import trange \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import sys\n",
    "from google.colab.patches import cv2_imshow\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c119b9",
   "metadata": {
    "id": "97c119b9"
   },
   "source": [
    "<div dir=rtl>\n",
    "\n",
    "# Question 1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37fa8cb",
   "metadata": {
    "id": "d37fa8cb"
   },
   "source": [
    "<div dir=rtl>\n",
    "در سلول بالا تمام ماژولهای لازم برای انجام پروژه را اضافه کرده ام.\n",
    "\n",
    "من برای پیاده سازی این تکلیف از فریمورک پایتورچ استفاده نموده ام.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79809c0b",
   "metadata": {
    "id": "79809c0b"
   },
   "outputs": [],
   "source": [
    "# PATH = \"C:\\\\uni\\\\1 - first term\\\\Deep Learning\\\\HW2 Practical\"\n",
    "# data_dir = PATH + '\\\\train' # load from Kaggle\n",
    "# data_dir = '/content/drive/MyDrive/data'\n",
    "transform = transforms.Compose([transforms.Resize(32),\n",
    "                                transforms.CenterCrop(32),\n",
    "                                transforms.ToTensor()\n",
    "                               ])# TODO: compose transforms here\n",
    "dataset = datasets.ImageFolder(data_dir, transform=transform) # TODO: create the ImageFolder\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True) # TODO: use the ImageFolder dataset to create the DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ujIlFSEbnCAY",
   "metadata": {
    "id": "ujIlFSEbnCAY"
   },
   "source": [
    "<div dir=rtl>\n",
    "در سلول بالا تمامی تصاویر دیتاست خوانده شده اند.\n",
    "\n",
    "به دلیل اینکه تصاویر ابعاد گوناگونی دارند در این سلول با استفاده از تبدیل transform همگی تصاویر را به ابعاد 32 در 32 کاهش بعد داده ام.\n",
    "\n",
    "سپس دیتالودرم را با استفاده از تصاویری که خوانده شده اند و ابعاد آنها تغییر یافته است در batch های 32تایی قرار داده ام و با فعال کردن درهم ریزی، ترتیب قرار گیری تصاویر از دو کلاس را بصورت رندوم تغییر داده ام.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccc5dfd",
   "metadata": {
    "id": "9ccc5dfd"
   },
   "outputs": [],
   "source": [
    "train_set_size = int(len(dataloader) * 0.8)\n",
    "test_set_size = len(dataloader) - train_set_size\n",
    "train_set, test_set = data.random_split(dataloader, [train_set_size, test_set_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BY4R7aQynwl5",
   "metadata": {
    "id": "BY4R7aQynwl5"
   },
   "source": [
    "<div dir=rtl>\n",
    "از آنجایی که در متن تکلیف گفته شده است 80 درصد تصاویر را برای آموزش و 20 درصد تصاویر را برای تست مدل اختصاص دهیم، \n",
    "\n",
    "در سلول بالا ابتدا اندازه دو دسته داده های آموزشی و تست را مشخص کرده ام \n",
    "\n",
    "و سپس با استفاده از تابع random_split دیتالودر اصلی را به دو دیتالودر برای آموزش و تست افراز کرده ام که هر یک به تعدادی که ما قبلا مشخص کرده ایم تصویر دارند.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e7dc08",
   "metadata": {
    "id": "68e7dc08"
   },
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None, normalize=True):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "\n",
    "    if normalize:\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image = std * image + mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.tick_params(axis='both', length=0)\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_yticklabels('')\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JTSMG2Eroqnm",
   "metadata": {
    "id": "JTSMG2Eroqnm"
   },
   "source": [
    "<div dir=rtl>\n",
    "در تابع بالا یک تنسور را برای نمایش بصورت یک تصویر آماده میکنیم\n",
    "\n",
    "سپس بررسی میکنیم اگر بنابر نرمال سازی تصویر بود آنرا با کمک وکتورهای میانگین و واریانس نرمال میکند،\n",
    "\n",
    "سپس تصویر نهایی را نمایش میدهد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc64ec6b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "fc64ec6b",
    "outputId": "8f8f541b-b81e-413f-9d91-7dcbf9bcac8e"
   },
   "outputs": [],
   "source": [
    "# Run this to test your data loader\n",
    "images, labels = next(iter(dataloader))\n",
    "imshow(images[0], normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GFCt88Z1qI_9",
   "metadata": {
    "id": "GFCt88Z1qI_9"
   },
   "source": [
    "<div dir=rtl>\n",
    "در اینجا یکی از تصاویر را بصورت رندوم نمایش میدهد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d5eef2",
   "metadata": {
    "id": "f8d5eef2"
   },
   "outputs": [],
   "source": [
    "class Nerwork_noDropout_noBatchNormalization(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 2, 1),  # in_channels, out_channels, kernel_size, stride, padding\n",
    "            nn.MaxPool2d(2),  # kernel_size\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 192, 3, padding=1),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(192, 384, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 2 * 2, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.classifier(h)\n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rb-b7j61qa_p",
   "metadata": {
    "id": "rb-b7j61qa_p"
   },
   "source": [
    "<div dir=rtl>\n",
    "در سلول بالا معماری اصلی شبکه آمده است.\n",
    "\n",
    ".\n",
    "\n",
    "برای ساخت تمامی مدلهایی که در سوال یک و دو استفاده میشود از همین معماری اصلی استفاده میشود و تنها لایه ی Batch Normalization و Dropout به آن اضافه میشود.\n",
    "\n",
    "این شبکه معماری ای شبیه به معماری شبکه alexnet دارد،\n",
    "\n",
    "در این شبکه دو قسمت اصلی وجود دارد،\n",
    "قسمت اول با هدف استخراج ویژگی از تصاویر نوشته شده است و قسمت دوم قصد دارد با استفاده از ویژگیهای استخراج شده تصاویر را دسته بندی کند.\n",
    "\n",
    ".\n",
    "\n",
    "در قسمت اول من از 5 لایه ی کانوولوشنی دوبعدی استفاده کردم،\n",
    "\n",
    "بعد از هر لایه ی کانوولوشنی یک لایه ی maxpool دو بعدی قرار میگیرد و،\n",
    "\n",
    "تابع فعالساز برای همه ی لایه ها تابع ReLU است\n",
    "\n",
    ".\n",
    "\n",
    "در قسمت دوم شبکه از سه لایه ی Linear و مجددا تابع فعالساز ReLU استفاده میکنیم.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e5edcf",
   "metadata": {
    "id": "c2e5edcf"
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight.data, nonlinearity='relu')\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight.data, gain=nn.init.calculate_gain('relu'))\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eJ7IdpEshmH",
   "metadata": {
    "id": "0eJ7IdpEshmH"
   },
   "source": [
    "<div dir=rtl>\n",
    "در این تابع با استفاده از روش kaiming_normal و xavier اقدام به مقداردهی اولیه به پارامترهای مدل میکنیم.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4j-UtYkY_jym",
   "metadata": {
    "id": "4j-UtYkY_jym"
   },
   "source": [
    "## قسمت آ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068045bd",
   "metadata": {
    "id": "068045bd"
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim=True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c16d07",
   "metadata": {
    "id": "36c16d07"
   },
   "outputs": [],
   "source": [
    "def calculate_precision(y_pred, y):\n",
    "    tp = (torch.max(y_pred, 1)[1].view(y.size()).data & y.data).sum()\n",
    "    fp = (torch.max((torch.logical_not(y_pred)), 1)[1].view(y.size()).data & (torch.logical_not(y)).data).sum()\n",
    "    precision = tp/(tp+fp)\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8756c44",
   "metadata": {
    "id": "a8756c44"
   },
   "outputs": [],
   "source": [
    "def calculate_recall(y_pred, y):\n",
    "    recall=metrics.recall_score((torch.max(y_pred, 1)[1]).cpu().numpy(), y.cpu().numpy())\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449ZkVLptA1z",
   "metadata": {
    "id": "449ZkVLptA1z"
   },
   "source": [
    "<div dir=rtl>\n",
    "در سه سلول بالا پیاده سازی توابع محاسبه ی Accuracy، Precision و Recall از روی مقادیر پیشبینی شده و مقادیر اصلی قابل مشاهده است.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cef9d9",
   "metadata": {
    "id": "64cef9d9"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_prec = 0\n",
    "    epoch_recall = 0\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    for (x, y) in tqdm(iterator, desc=\"Training\", leave=False):\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred, _ = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "        prec = calculate_precision(y_pred, y)\n",
    "        recall = calculate_recall(y_pred, y)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        epoch_prec += prec.item()\n",
    "        epoch_recall += recall\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_prec / len(iterator), epoch_recall / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sXqsn2wntU68",
   "metadata": {
    "id": "sXqsn2wntU68"
   },
   "source": [
    "<div dir=rtl>\n",
    "از این تابع برای پیاده سازی آموزش مدل استفاده میکنیم.\n",
    "\n",
    ".\n",
    "\n",
    "تابع به این صورت کار میکند که مدل، دیتالودر آموزش، تابع محاسبه loss مدل و نوع device در دسترس را دریافت نموده،\n",
    "\n",
    "سپس تک تک داده های آموزش را به مدل نشان داده، \n",
    "مقدار پیشبینی شده را از مدل دریافت میکند،\n",
    "با استفاده از مقدار پیشبینی شده و مقدار واقعی مقدار loss را محاسبه میکند،\n",
    "\n",
    "سپس با استفاده از مقدار loss محاسبه شده جدید برای وزن ها و بایاس ها در گام loss.backward() محاسبه میشود،\n",
    " سپس با توجه به مقادیر جدید در گام optimizer.step() مدل optimize میشود.\n",
    "\n",
    " در هر گام سه معیار accuracy، precision و recall محاسبه میشود و نهایتا در آخر آموزش میانگین این سه مقدار به همراه میانگین loss بازگردانده میشود.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c21541d",
   "metadata": {
    "id": "7c21541d"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_prec = 0\n",
    "    epoch_recall = 0\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "#         for (x, y) in tqdm(iterator, desc=\"Evaluating\", leave=False):\n",
    "        for x, y in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred, _ = model(x)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "            prec = calculate_precision(y_pred, y)\n",
    "            recall = calculate_recall(y_pred, y)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_prec += prec.item()\n",
    "            epoch_recall += recall\n",
    "           \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_prec / len(iterator), epoch_recall / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dip5YrKExI1A",
   "metadata": {
    "id": "dip5YrKExI1A"
   },
   "source": [
    "<div dir=rtl>\n",
    "در این تابع قسمت ارزیابی مدل با استفاده از داده های تست پیاده سازی شده است.\n",
    "\n",
    ".\n",
    "\n",
    "در این قسمت همه ی داده های تست بصورت تک به تک به مدل نشان داده شده اند و از روی مقدار پیش بینی شده برای آنها مقدار loss، accuracy، precision و recall محاسبه میشود.\n",
    "\n",
    "نهایتا میانگین این چهار مقدار به عنوان نتیجه ارزیابی مدل روی داده های تست بازگردانده میشود.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f60e3f5",
   "metadata": {
    "id": "7f60e3f5"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OnGPV1o1x2XG",
   "metadata": {
    "id": "OnGPV1o1x2XG"
   },
   "source": [
    "<div dir=rtl>\n",
    "در این تابع با دریافت زمان شروع و زمان پایان فرآیند مقدار دقایق و ثانیه های صرق شده محاسبه میشود.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Nwlc5g0g_0CZ",
   "metadata": {
    "id": "Nwlc5g0g_0CZ"
   },
   "source": [
    "## قسمت ب"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb2116c",
   "metadata": {
    "id": "3eb2116c",
    "outputId": "4a0e196b-6a20-4d22-8407-05b8168e80bb"
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIM = 2\n",
    "model_noDropout_noBatch_adam = Nerwork_noDropout_noBatchNormalization(OUTPUT_DIM)\n",
    "model_noDropout_noBatch_adam.apply(initialize_parameters)\n",
    "model_noDropout_noBatch_adam = model_noDropout_noBatch_adam.to(device)\n",
    "FOUND_LR = 1e-3\n",
    "EPOCHS=5\n",
    "optimizer = optim.Adam(model_noDropout_noBatch_adam.parameters(), lr=FOUND_LR)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "loss = []\n",
    "acc = []\n",
    "epochs = []\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in trange(EPOCHS, desc=\"Epochs\"):\n",
    "\n",
    "    start_time = time.monotonic()\n",
    "    train_loss, train_acc, train_prec, train_recall = train(model_noDropout_noBatch_adam, train_set.dataset, optimizer, criterion, device)\n",
    "    loss.append(train_loss)\n",
    "    acc.append(train_acc)\n",
    "    epochs.append(epoch)\n",
    "\n",
    "    torch.save(model_noDropout_noBatch_adam.state_dict(), 'model_noDropout_noBatch_adam.pt')\n",
    "\n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Train Prec: {train_prec*100:.2f}% | Train recall: {train_recall*100:.2f}%')\n",
    "\n",
    "plt.plot(epochs, loss)\n",
    "plt.plot(epochs, acc)\n",
    "plt.plot(epochs, loss, 'g', label='Training loss')\n",
    "plt.plot(epochs, acc, 'r', label='validation loss')\n",
    "plt.title('Training loss and Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss and Acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EvFnWY3x6L2u",
   "metadata": {
    "id": "EvFnWY3x6L2u"
   },
   "source": [
    "<div dir=rtl>\n",
    "در سلول بالا اولین مدل مبتنی بر شبکه Nerwork_noDropout_noBatchNormalization را آموزش داده ایم.\n",
    "\n",
    "از تابع initialize_parameters برای مقداردهی اولیه به وزنها و بایاسهای شبکه استفاده شده است.\n",
    "\n",
    "برای آموزش این مدل از تابع بهینه سازی Adam استفاده کرده ام،\n",
    "\n",
    "فرآیند آموزش برای 5 ایپاک انجام شده است،\n",
    "\n",
    "از تابع CrossEntropyLoss برای محاسبه loss مدل استفاده شده است،\n",
    "\n",
    "نهایتا مدل، دیتالودر آموزش، optimizer و تابع محاسبه loss به تابع train داده شده است و این فرآیند به تعداد ایپاکها یعنی 5 بار تکرار شده است.\n",
    "\n",
    "در پایان هر ایپاک مقدار loss، accuracy، precision و recall محاسبه شده اند و نمایش داده میشوند.\n",
    "\n",
    "نهایتا همانطور که خواسته شده نمودار مقدار loss و accuracy فرآیند آموزش نمایش داده میشود.\n",
    "\n",
    ".\n",
    "\n",
    "در این فرآیند آموزش، از شبکه ای بدون Batch Normalization و Dropout و تابع بهینه سازی Adam استفاده کردم و مشاهده شده در پایان آموزش به دقت 94.34 درصد برای داده های آموزشی رسیدم.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c923c9",
   "metadata": {
    "id": "26c923c9",
    "outputId": "de2a3ef1-aa11-48c3-ac56-4ee22f3127a4"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc, test_prec, test_recall = evaluate(model_noDropout_noBatch_adam, test_set.dataset, criterion, device)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | Test Precision: {test_prec:.3f} | Test Recall: {test_recall*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zjszFtPY8Wni",
   "metadata": {
    "id": "zjszFtPY8Wni"
   },
   "source": [
    "<div dir=rtl>\n",
    "در سلول بالا فرآیند ارزیابی مدل روی داده های تست به وسیله ی تابع evaluate انجام شده است.\n",
    "\n",
    "برای این بررسی 4 مقدار loss، accuracy، precision و recall نمایش داده شده است.\n",
    "\n",
    ".\n",
    "در این قسمت، از شبکه ای بدون Batch Normalization و Dropout و تابع بهینه ساز Adam استفاده کردم و مشاهده شده در دقت مدل برای داده های تست برابر با 94.65 درصد می باشد.\n",
    "\n",
    ".\n",
    "\n",
    "از آنجایی که دقت آموزش و تست هر دو حدود 94 درصد هستند نتیجه میگیریم شبکه، شبکه مناسبی بوده است و احتمال کمی وجود دارد که شبکه دچار overfit شده باشد.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225dde2f",
   "metadata": {
    "id": "225dde2f",
    "outputId": "54dcce0d-a612-414d-8ebb-86bed438fdac"
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIM = 2\n",
    "model_noDropout_noBatch_sgd = Nerwork_noDropout_noBatchNormalization(OUTPUT_DIM)\n",
    "model_noDropout_noBatch_sgd.apply(initialize_parameters)\n",
    "model_noDropout_noBatch_sgd = model_noDropout_noBatch_sgd.to(device)\n",
    "FOUND_LR = 1e-3\n",
    "EPOCHS=5\n",
    "optimizer = optim.SGD(model_noDropout_noBatch_sgd.parameters(), lr=FOUND_LR, momentum=0.9)\n",
    "\n",
    "loss = []\n",
    "acc = []\n",
    "epochs = []\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in trange(EPOCHS, desc=\"Epochs\"):\n",
    "\n",
    "    start_time = time.monotonic()\n",
    "    train_loss, train_acc, train_prec, train_recall = train(model_noDropout_noBatch_sgd, train_set.dataset, optimizer, criterion, device)\n",
    "    loss.append(train_loss)\n",
    "    acc.append(train_acc)\n",
    "    epochs.append(epoch)\n",
    "    \n",
    "    torch.save(model_noDropout_noBatch_sgd.state_dict(), 'model_noDropout_noBatch_sgd.pt')\n",
    "\n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Train Prec: {train_prec*100:.2f}% | Train recall: {train_recall*100:.2f}%')\n",
    "\n",
    "plt.plot(epochs, loss)\n",
    "plt.plot(epochs, acc)\n",
    "plt.plot(epochs, loss, 'g', label='Training loss')\n",
    "plt.plot(epochs, acc, 'r', label='validation loss')\n",
    "plt.title('Training loss and Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss and Acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wtGBz0Pb9oE8",
   "metadata": {
    "id": "wtGBz0Pb9oE8"
   },
   "source": [
    "<div dir=rtl>\n",
    "\n",
    "در سلول بالا دومین مدل مبتنی بر شبکه Nerwork_noDropout_noBatchNormalization را آموزش داده ایم.\n",
    "\n",
    "از تابع initialize_parameters برای مقداردهی اولیه به وزنها و بایاسهای شبکه استفاده شده است.\n",
    "\n",
    "برای آموزش این مدل از تابع بهینه سازی SGD استفاده کرده ام،\n",
    "\n",
    "فرآیند آموزش برای 5 ایپاک انجام شده است،\n",
    "\n",
    "از تابع CrossEntropyLoss برای محاسبه loss مدل استفاده شده است،\n",
    "\n",
    "نهایتا مدل، دیتالودر آموزش، optimizer و تابع محاسبه loss به تابع train داده شده است و این فرآیند به تعداد ایپاکها یعنی 5 بار تکرار شده است.\n",
    "\n",
    "در پایان هر ایپاک مقدار loss، accuracy، precision و recall محاسبه شده اند و نمایش داده میشوند.\n",
    "\n",
    "نهایتا همانطور که خواسته شده نمودار مقدار loss و accuracy فرآیند آموزش نمایش داده میشود.\n",
    "\n",
    ".\n",
    "\n",
    "در این فرآیند آموزش، از شبکه ای بدون Batch Normalization و Dropout و تابع بهینه سازی SGD استفاده کردم و مشاهده شده در پایان آموزش به دقت 93.78 درصد برای داده های آموزشی رسیدم.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef813f5",
   "metadata": {
    "id": "2ef813f5",
    "outputId": "523c7306-859f-4556-96f5-b2edc53fe217"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc, test_prec, test_recall = evaluate(model_noDropout_noBatch_sgd, test_set.dataset, criterion, device)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | Test Precision: {test_prec:.3f} | Test Recall: {test_recall*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o4QbPl-d-bRt",
   "metadata": {
    "id": "o4QbPl-d-bRt"
   },
   "source": [
    "<div dir=rtl>\n",
    "\n",
    "در سلول بالا فرآیند ارزیابی مدل روی داده های تست به وسیله ی تابع evaluate انجام شده است.\n",
    "\n",
    "برای این بررسی 4 مقدار loss، accuracy، precision و recall نمایش داده شده است.\n",
    "\n",
    ".\n",
    "در این قسمت، از شبکه ای بدون Batch Normalization و Dropout و تابع بهینه ساز SGD استفاده کردم و مشاهده شده در دقت مدل برای داده های تست برابر با 95.27 درصد می باشد.\n",
    "\n",
    ".\n",
    "\n",
    "از آنجایی که دقت آموزش حدود 93 درصد و دقت تست حدود 95 درصد هستند نتیجه میگیریم شبکه، شبکه مناسبی بوده است و احتمال کمی وجود دارد که شبکه دچار overfit شده باشد.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205b1347",
   "metadata": {
    "id": "205b1347",
    "outputId": "71aaa0c4-161d-4e40-dd35-268bc8f80176"
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIM = 2\n",
    "model_noDropout_noBatch_rmsprop = Nerwork_noDropout_noBatchNormalization(OUTPUT_DIM)\n",
    "model_noDropout_noBatch_rmsprop.apply(initialize_parameters)\n",
    "model_noDropout_noBatch_rmsprop = model_noDropout_noBatch_rmsprop.to(device)\n",
    "FOUND_LR = 1e-3\n",
    "EPOCHS=5\n",
    "optimizer = optim.RMSprop(model_noDropout_noBatch_rmsprop.parameters(), lr=FOUND_LR)\n",
    "\n",
    "loss = []\n",
    "acc = []\n",
    "epochs = []\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in trange(EPOCHS, desc=\"Epochs\"):\n",
    "\n",
    "    start_time = time.monotonic()\n",
    "    train_loss, train_acc, train_prec, train_recall = train(model_noDropout_noBatch_rmsprop, train_set.dataset, optimizer, criterion, device)\n",
    "    loss.append(train_loss)\n",
    "    acc.append(train_acc)\n",
    "    epochs.append(epoch)\n",
    "\n",
    "    torch.save(model_noDropout_noBatch_rmsprop.state_dict(), 'model_noDropout_noBatch_rmsprop.pt')\n",
    "\n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Train Prec: {train_prec*100:.2f}% | Train recall: {train_recall*100:.2f}%')\n",
    "\n",
    "plt.plot(epochs, loss)\n",
    "plt.plot(epochs, acc)\n",
    "plt.plot(epochs, loss, 'g', label='Training loss')\n",
    "plt.plot(epochs, acc, 'r', label='validation loss')\n",
    "plt.title('Training loss and Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss and Acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "N23vtiTE-tgu",
   "metadata": {
    "id": "N23vtiTE-tgu"
   },
   "source": [
    "<div dir=rtl>\n",
    "\n",
    "در سلول بالا سومین مدل مبتنی بر شبکه Nerwork_noDropout_noBatchNormalization را آموزش داده ایم.\n",
    "\n",
    "از تابع initialize_parameters برای مقداردهی اولیه به وزنها و بایاسهای شبکه استفاده شده است.\n",
    "\n",
    "برای آموزش این مدل از تابع بهینه سازی RMSProp استفاده کرده ام،\n",
    "\n",
    "فرآیند آموزش برای 5 ایپاک انجام شده است،\n",
    "\n",
    "از تابع CrossEntropyLoss برای محاسبه loss مدل استفاده شده است،\n",
    "\n",
    "نهایتا مدل، دیتالودر آموزش، optimizer و تابع محاسبه loss به تابع train داده شده است و این فرآیند به تعداد ایپاکها یعنی 5 بار تکرار شده است.\n",
    "\n",
    "در پایان هر ایپاک مقدار loss، accuracy، precision و recall محاسبه شده اند و نمایش داده میشوند.\n",
    "\n",
    "نهایتا همانطور که خواسته شده نمودار مقدار loss و accuracy فرآیند آموزش نمایش داده میشود.\n",
    "\n",
    ".\n",
    "\n",
    "در این فرآیند آموزش، از شبکه ای بدون Batch Normalization و Dropout و تابع بهینه سازی RMSProp استفاده کردم و مشاهده شده در پایان آموزش به دقت 89.53 درصد برای داده های آموزشی رسیدم.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8908be",
   "metadata": {
    "id": "6a8908be",
    "outputId": "a236ac9e-9b29-44db-e013-b440ee479cb7"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc, test_prec, test_recall = evaluate(model_noDropout_noBatch_rmsprop, test_set.dataset, criterion, device)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | Test Precision: {test_prec:.3f} | Test Recall: {test_recall*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q-V1b7Ng_IPi",
   "metadata": {
    "id": "q-V1b7Ng_IPi"
   },
   "source": [
    "<div dir=rtl>\n",
    "\n",
    "در سلول بالا فرآیند ارزیابی مدل روی داده های تست به وسیله ی تابع evaluate انجام شده است.\n",
    "\n",
    "برای این بررسی 4 مقدار loss، accuracy، precision و recall نمایش داده شده است.\n",
    "\n",
    ".\n",
    "در این قسمت، از شبکه ای بدون Batch Normalization و Dropout و تابع بهینه ساز RMSProp استفاده کردم و مشاهده شده در دقت مدل برای داده های تست برابر با 92.54 درصد می باشد.\n",
    "\n",
    ".\n",
    "\n",
    "از آنجایی که دقت آموزش حدود 89 درصد و دقت تست حدود 92 درصد هستند نتیجه میگیریم شبکه، شبکه مناسبی بوده است و احتمال کمی وجود دارد که شبکه دچار overfit شده باشد.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pVJ9JmZQAfR1",
   "metadata": {
    "id": "pVJ9JmZQAfR1"
   },
   "source": [
    "## قسمت پ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YXka7x0uAhDx",
   "metadata": {
    "id": "YXka7x0uAhDx"
   },
   "source": [
    "<div dir=rtl>\n",
    "\n",
    "تا کنون سه مدل آموزش داده ایم و عملکرد آنها را روی داده های آموزش و تست بررسی کرده ایم.\n",
    "\n",
    ".\n",
    "\n",
    "برای تمام مدل ها از شبکه Nerwork_noDropout_noBatchNormalization استفاده کرده ام.\n",
    "\n",
    "* در اولین مدل از تابع بهینه ساز Adam استفاده کردم و به دقت 94.34 درصد برای داده های آموزشی و دقت 94.65 برای داده های تست رسیده ام\n",
    "\n",
    "* در دومین مدل از تابع بهینه ساز SGD استفاده کردم و به دقت 93.78 برای داده های آموزشی و دقت 95.27 برای داده های تست رسیدم.\n",
    "\n",
    "* در سومین مدل از تابع بهینه ساز RMSProp استفاده کردم و دقت مدل برای داده های آموزش به 89.53 و برای داده های تست برابر با 92.54 درصد شد.\n",
    "\n",
    ".\n",
    "\n",
    "از مقایسه نتایج این سه مدل نتیجه میگیریم دقت آموزش مدلی که با تابع بهینه ساز Adam آموزش دیده بود از همه ی مدلها بیشتر است و عملکرد مدلی که توسط بهینه ساز SGD آموزش دیده بود بهترین عملکرد را روی دسته بندی داده های تست دارد.\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "حال که دیدیم تابع بهینه ساز SGD برای شبکه ما بهترین نتیجه روی داده های تست را به ارمغان آورده، در ادامه این پروژه از همین تابع برای بهینه سازی مدل استفاده میکنم\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KtwUIoPmCeq3",
   "metadata": {
    "id": "KtwUIoPmCeq3"
   },
   "source": [
    "## قسمت ت"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d6539f",
   "metadata": {
    "id": "46d6539f"
   },
   "outputs": [],
   "source": [
    "class Nerwork_Dropout_noBatchNormalization(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 2, 1),  # in_channels, out_channels, kernel_size, stride, padding\n",
    "            nn.MaxPool2d(2),  # kernel_size\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 192, 3, padding=1),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(192, 384, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256 * 2 * 2, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.classifier(h)\n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MHk4zuXcCzyh",
   "metadata": {
    "id": "MHk4zuXcCzyh"
   },
   "source": [
    "<div dir=rtl>\n",
    "\n",
    "شبکه مادری که در قسمت قبل معرفی کرده بودم را درنظربگیرید. \n",
    "\n",
    "در این قسمت تنها با اضافه کردن دو لایه Dropout در قسمت Classifier شبکه سعی میکنم فرآیند Regularization را انجام دهم.\n",
    "\n",
    "پارامتر Dropout را در این شبکه برابر با 0.5 قرار داده ام.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a98b19c",
   "metadata": {
    "id": "6a98b19c",
    "outputId": "096aa19a-2ec0-472f-f90d-c842d8e5421d"
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIM = 2\n",
    "model_sgd_dropout = Nerwork_Dropout_noBatchNormalization(OUTPUT_DIM)\n",
    "model_sgd_dropout.apply(initialize_parameters)\n",
    "model_sgd_dropout = model_sgd_dropout.to(device)\n",
    "FOUND_LR = 1e-3\n",
    "EPOCHS=5\n",
    "optimizer = optim.SGD(model_sgd_dropout.parameters(), lr=FOUND_LR, momentum=0.9)\n",
    "\n",
    "loss = []\n",
    "acc = []\n",
    "epochs = []\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in trange(EPOCHS, desc=\"Epochs\"):\n",
    "\n",
    "    start_time = time.monotonic()\n",
    "    train_loss, train_acc, train_prec, train_recall = train(model_sgd_dropout, train_set.dataset, optimizer, criterion, device)\n",
    "    loss.append(train_loss)\n",
    "    acc.append(train_acc)\n",
    "    epochs.append(epoch)\n",
    "    \n",
    "    torch.save(model_sgd_dropout.state_dict(), 'model_sgd_dropout.pt')\n",
    "\n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Train Prec: {train_prec*100:.2f}% | Train recall: {train_recall*100:.2f}%')\n",
    "\n",
    "plt.plot(epochs, loss)\n",
    "plt.plot(epochs, acc)\n",
    "plt.plot(epochs, loss, 'g', label='Training loss')\n",
    "plt.plot(epochs, acc, 'r', label='validation loss')\n",
    "plt.title('Training loss and Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss and Acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o6g5jI0tD3lK",
   "metadata": {
    "id": "o6g5jI0tD3lK"
   },
   "source": [
    "<div dir=rtl>\n",
    "\n",
    "در سلول بالا مدل مبتنی بر شبکه Nerwork_Dropout_noBatchNormalization را آموزش داده ایم.\n",
    "\n",
    "از تابع initialize_parameters برای مقداردهی اولیه به وزنها و بایاسهای شبکه استفاده شده است.\n",
    "\n",
    "برای آموزش این مدل از تابع بهینه سازی SGD استفاده کرده ام،\n",
    "\n",
    "فرآیند آموزش برای 5 ایپاک انجام شده است،\n",
    "\n",
    "از تابع CrossEntropyLoss برای محاسبه loss مدل استفاده شده است،\n",
    "\n",
    "نهایتا مدل، دیتالودر آموزش، optimizer و تابع محاسبه loss به تابع train داده شده است و این فرآیند به تعداد ایپاکها یعنی 5 بار تکرار شده است.\n",
    "\n",
    "در پایان هر ایپاک مقدار loss، accuracy، precision و recall محاسبه شده اند و نمایش داده میشوند.\n",
    "\n",
    "نهایتا همانطور که خواسته شده نمودار مقدار loss و accuracy فرآیند آموزش نمایش داده میشود.\n",
    "\n",
    ".\n",
    "\n",
    "در این فرآیند آموزش، از شبکه ای با Dropout و بدون Batch Normalization و تابع بهینه سازی SGD استفاده کردم و مشاهده شده در پایان آموزش به دقت 91.31 درصد برای داده های آموزشی رسیدم.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53382e30",
   "metadata": {
    "id": "53382e30",
    "outputId": "195f84a5-1863-40dc-c127-eb0fcafd15f6"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc, test_prec, test_recall = evaluate(model_sgd_dropout, test_set.dataset, criterion, device)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | Test Precision: {test_prec:.3f} | Test Recall: {test_recall*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XI4y2smzETqz",
   "metadata": {
    "id": "XI4y2smzETqz"
   },
   "source": [
    "<div dir=rtl>\n",
    "\n",
    "در سلول بالا فرآیند ارزیابی مدل روی داده های تست به وسیله ی تابع evaluate انجام شده است.\n",
    "\n",
    "برای این بررسی 4 مقدار loss، accuracy، precision و recall نمایش داده شده است.\n",
    "\n",
    ".\n",
    "در این قسمت، از شبکه ای با Dropout و  بدون Batch Normalization و تابع بهینه ساز SGD استفاده کردم و مشاهده شده در دقت مدل برای داده های تست برابر با 92.62 درصد می باشد.\n",
    "\n",
    ".\n",
    "\n",
    "از آنجایی که دقت آموزش حدود 91 درصد و دقت تست حدود 92 درصد هستند نتیجه میگیریم شبکه، شبکه مناسبی بوده است و احتمال کمی وجود دارد که شبکه دچار overfit شده باشد.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fSMdFDdH7Bi",
   "metadata": {
    "id": "9fSMdFDdH7Bi"
   },
   "source": [
    "<div dir=rtl>\n",
    "\n",
    "با مقایسه نتیجه مدل بدون لایه ی Dropout و مدل با لایه ی Dropout نتیجه میگیریم که افزودن این لایه منجر شده عملکرد مدل افت پیدا کند و از دقت 95.27 درصد برای داده های تست به 92.62 برای داده های تست برسد.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VT05X_mdE7cn",
   "metadata": {
    "id": "VT05X_mdE7cn"
   },
   "source": [
    "## قسمت س"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf18802",
   "metadata": {
    "id": "bdf18802"
   },
   "outputs": [],
   "source": [
    "class Nerwork_Dropout_BatchNormalization(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 2, 1),  # in_channels, out_channels, kernel_size, stride, padding\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2),  # kernel_size\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 192, 3, padding=1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(192, 384, 3, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256 * 2 * 2, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.classifier(h)\n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aMAuBiurFEaT",
   "metadata": {
    "id": "aMAuBiurFEaT"
   },
   "source": [
    "<div dir=rtl>\n",
    "\n",
    "حال معماری شبکه قبلی که دارای لایه ی Dropout بود را در نظر بگیرید.\n",
    "\n",
    "قصد داریم به همان شبکه لایه های Batch Normalization نیز اضافه کنیم،\n",
    "\n",
    "برای این کار کافی است لایه های BatchNorm2d با ابعاد ورودی مناسب را بعد از لایه های conv2d اضافه کنیم.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be868dce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "be868dce",
    "outputId": "d9adbdcc-8f23-44d9-9f3a-1c2f2e1b817b"
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIM = 2\n",
    "model_sgd_dropout_batch = Nerwork_Dropout_BatchNormalization(OUTPUT_DIM)\n",
    "model_sgd_dropout_batch.apply(initialize_parameters)\n",
    "model_sgd_dropout_batch = model_sgd_dropout_batch.to(device)\n",
    "FOUND_LR = 1e-3\n",
    "EPOCHS=5\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)\n",
    "optimizer = optim.SGD(model_sgd_dropout_batch.parameters(), lr=FOUND_LR, momentum=0.9)\n",
    "\n",
    "loss = []\n",
    "acc = []\n",
    "epochs = []\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in trange(EPOCHS, desc=\"Epochs\"):\n",
    "\n",
    "    start_time = time.monotonic()\n",
    "    train_loss, train_acc, train_prec, train_recall = train(model_sgd_dropout_batch, train_set.dataset, optimizer, criterion, device)\n",
    "    loss.append(train_loss)\n",
    "    acc.append(train_acc)\n",
    "    epochs.append(epoch)\n",
    "    \n",
    "    torch.save(model_sgd_dropout_batch.state_dict(), 'model_sgd_dropout_batch.pt')\n",
    "\n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Train Prec: {train_prec*100:.2f}% | Train recall: {train_recall*100:.2f}%')\n",
    "\n",
    "plt.plot(epochs, loss)\n",
    "plt.plot(epochs, acc)\n",
    "plt.plot(epochs, loss, 'g', label='Training loss')\n",
    "plt.plot(epochs, acc, 'r', label='validation loss')\n",
    "plt.title('Training loss and Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss and Acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uRMppiYWHPLv",
   "metadata": {
    "id": "uRMppiYWHPLv"
   },
   "source": [
    "<div dir=rtl>\n",
    "\n",
    "در سلول بالا مدل مبتنی بر شبکه Nerwork_Dropout_noBatchNormalization را آموزش داده ایم.\n",
    "\n",
    "از تابع initialize_parameters برای مقداردهی اولیه به وزنها و بایاسهای شبکه استفاده شده است.\n",
    "\n",
    "برای آموزش این مدل از تابع بهینه سازی SGD استفاده کرده ام،\n",
    "\n",
    "فرآیند آموزش برای 5 ایپاک انجام شده است،\n",
    "\n",
    "از تابع CrossEntropyLoss برای محاسبه loss مدل استفاده شده است،\n",
    "\n",
    "نهایتا مدل، دیتالودر آموزش، optimizer و تابع محاسبه loss به تابع train داده شده است و این فرآیند به تعداد ایپاکها یعنی 5 بار تکرار شده است.\n",
    "\n",
    "در پایان هر ایپاک مقدار loss، accuracy، precision و recall محاسبه شده اند و نمایش داده میشوند.\n",
    "\n",
    "نهایتا همانطور که خواسته شده نمودار مقدار loss و accuracy فرآیند آموزش نمایش داده میشود.\n",
    "\n",
    ".\n",
    "\n",
    "در این فرآیند آموزش، از شبکه ای با Dropout و Batch Normalization و تابع بهینه سازی SGD استفاده کردم و مشاهده شده در پایان آموزش به دقت 93.86 درصد برای داده های آموزشی رسیدم.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08709a77",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08709a77",
    "outputId": "de4c6d01-0309-4a95-c46a-04d5f51046b5"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc, test_prec, test_recall = evaluate(model_sgd_dropout_batch, test_set.dataset, criterion, device)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | Test Precision: {test_prec:.3f} | Test Recall: {test_recall*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gC5Ld_-BHbsx",
   "metadata": {
    "id": "gC5Ld_-BHbsx"
   },
   "source": [
    "<div dir=rtl>\n",
    "\n",
    "در سلول بالا فرآیند ارزیابی مدل روی داده های تست به وسیله ی تابع evaluate انجام شده است.\n",
    "\n",
    "برای این بررسی 4 مقدار loss، accuracy، precision و recall نمایش داده شده است.\n",
    "\n",
    ".\n",
    "در این قسمت، از شبکه ای با Dropout و Batch Normalization و تابع بهینه ساز SGD استفاده کردم و مشاهده شده در دقت مدل برای داده های تست برابر با 97.85 درصد می باشد.\n",
    "\n",
    ".\n",
    "\n",
    "از آنجایی که دقت آموزش حدود 93 درصد و دقت تست حدود 98 درصد هستند نتیجه میگیریم شبکه، شبکه مناسبی بوده است و احتمال کمی وجود دارد که شبکه دچار overfit شده باشد.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aKQ34Co6JqLA",
   "metadata": {
    "id": "aKQ34Co6JqLA"
   },
   "source": [
    "## قسمت ج"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y8WhnsOCIaLe",
   "metadata": {
    "id": "y8WhnsOCIaLe"
   },
   "source": [
    "<div dir=rtl>\n",
    "\n",
    "حال در این قسمت سه مدلی که همگی با تابع بهینه ساز SGD آموزش دیده اند و تنها در ساختار شبکه با هم متفاوت بودند را بررسی میکنیم.\n",
    "\n",
    "* مدل Nerwork_noDropout_noBatchNormalization در زمان آموزش به دقت 93.78 و در زمان تست به دقت 95.27 رسید.\n",
    "\n",
    "* مدل Nerwork_Dropout_noBatchNormalization در زمان آموزش به دقت 91.31 و در زمان تست به دقت 92.62 رسید.\n",
    "\n",
    "* مدل Nerwork_Dropout_BatchNormalization در زمان آموزش به دقت 93.86 و در زمان تست به دقت 97.85 رسید.\n",
    "\n",
    ".\n",
    "\n",
    "پس مشاهده میکنیم مدل آخر با وجود اینکه در زمان آموزش عملکردی متناسب با عملکرد اولین مدل داشته است ولی در زمان تست با اختلاف زیادی بهتر عمل کرده است و به وضوح میتوان تاثیر اضافه کردن لایه ی Dropout و Batch Normalization را در این قسمت مشاهده کرد.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7762e0ed",
   "metadata": {
    "id": "7762e0ed"
   },
   "source": [
    "## قسمت چ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3kJgROTvKAvo",
   "metadata": {
    "id": "3kJgROTvKAvo"
   },
   "source": [
    "<div dir=rtl>\n",
    "\n",
    "در سلول های زیر توابعی که قبلا برای ساخت دیتالودر، ساخت شبکه و آموزش مدل نوشته بودیم را متناسب با نیاز ماژول wandb تغییر میدهیم\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde47fa5",
   "metadata": {
    "id": "bde47fa5"
   },
   "outputs": [],
   "source": [
    "def build_dataset(batch_size):\n",
    "   \n",
    "    # PATH = \"C:\\\\uni\\\\1 - first term\\\\Deep Learning\\\\HW2 Practical\"\n",
    "    # data_dir = PATH + '\\\\train' # load from Kaggle\n",
    "    data_dir = '/content/drive/MyDrive/data'\n",
    "    transform = transforms.Compose([transforms.Resize(32),\n",
    "                                    transforms.CenterCrop(32),\n",
    "                                    transforms.ToTensor()\n",
    "                                   ])# TODO: compose transforms here\n",
    "    dataset = datasets.ImageFolder(data_dir, transform=transform) # TODO: create the ImageFolder\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True) # TODO: use the ImageFolder dataset to create the DataLoader\n",
    "\n",
    "    train_set_size = int(len(dataloader) * 0.8)\n",
    "    test_set_size = len(dataloader) - train_set_size\n",
    "    train_set, test_set = data.random_split(dataloader, [train_set_size, test_set_size])\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596cdd15",
   "metadata": {
    "id": "596cdd15"
   },
   "outputs": [],
   "source": [
    "class Nerwork_Dropout_BatchNormalization_build(nn.Module):\n",
    "    def __init__(self, output_dim, dropout, batch_normalization):\n",
    "        super().__init__()\n",
    "        if batch_normalization == True:\n",
    "            self.features = nn.Sequential(\n",
    "                nn.Conv2d(3, 64, 3, 2, 1),  # in_channels, out_channels, kernel_size, stride, padding\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.MaxPool2d(2),  # kernel_size\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(64, 192, 3, padding=1),\n",
    "                nn.BatchNorm2d(192),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(192, 384, 3, padding=1),\n",
    "                nn.BatchNorm2d(384),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(384, 256, 3, padding=1),\n",
    "                nn.BatchNorm2d(256),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(256, 256, 3, padding=1),\n",
    "                nn.BatchNorm2d(256),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(256 * 2 * 2, 4096),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(4096, 4096),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(4096, output_dim),\n",
    "            )\n",
    "        else:\n",
    "            self.features = nn.Sequential(\n",
    "                nn.Conv2d(3, 64, 3, 2, 1),  # in_channels, out_channels, kernel_size, stride, padding\n",
    "                nn.MaxPool2d(2),  # kernel_size\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(64, 192, 3, padding=1),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(192, 384, 3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(384, 256, 3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(256, 256, 3, padding=1),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(256 * 2 * 2, 4096),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(4096, 4096),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(4096, output_dim),\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.classifier(h)\n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2caf819",
   "metadata": {
    "id": "f2caf819"
   },
   "outputs": [],
   "source": [
    "def build_network(OUTPUT_DIM, dropout, batch_normalization):\n",
    "    network = Nerwork_Dropout_BatchNormalization_build(OUTPUT_DIM, dropout, batch_normalization)\n",
    "    return network.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bd91e9",
   "metadata": {
    "id": "12bd91e9"
   },
   "outputs": [],
   "source": [
    "def build_optimizer(network, optimizer, learning_rate):\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = optim.SGD(network.parameters(),\n",
    "                              lr=learning_rate, momentum=0.9)\n",
    "    elif optimizer == \"adam\":\n",
    "        optimizer = optim.Adam(network.parameters(),\n",
    "                               lr=learning_rate)\n",
    "    \n",
    "    elif optimizer == \"rmsprop\":\n",
    "        optimizer = optim.RMSprop(network.parameters(), \n",
    "                                  lr=learning_rate)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u6W1DfF3KZua",
   "metadata": {
    "id": "u6W1DfF3KZua"
   },
   "source": [
    "<div dir=rtl>\n",
    "\n",
    "این تابع برای استفاده از توابع بهینه ساز گوناگون نوشته شده است.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39a00bb",
   "metadata": {
    "id": "f39a00bb"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, iterator, optimizer, criterion, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_prec = 0\n",
    "    epoch_recall = 0\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    for (x, y) in tqdm(iterator, desc=\"Training\", leave=False):\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred, _ = model(x)\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "        prec = calculate_precision(y_pred, y)\n",
    "        recall = calculate_recall(y_pred, y)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        wandb.log({\"batch loss\": loss.item()})\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        epoch_prec += prec.item()\n",
    "        epoch_recall += recall\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_prec / len(iterator), epoch_recall / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60bf570",
   "metadata": {
    "id": "c60bf570"
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIM = 2\n",
    "def train(config=None):\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "\n",
    "        train_set, test_set = build_dataset(config.batch_size)\n",
    "        network = build_network(OUTPUT_DIM, config.dropout, config.batch_normalization)\n",
    "        optimizer = build_optimizer(network, config.optimizer, config.learning_rate)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        criterion = criterion.to(device)\n",
    "        for epoch in trange(config.epochs, desc=\"Epochs\"):\n",
    "            train_loss, train_acc, train_prec, train_recall = train_epoch(network, train_set.dataset, optimizer, criterion, device)\n",
    "            wandb.log({\"loss\": train_loss, \"epoch\": epoch})           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OYwc41lVKk29",
   "metadata": {
    "id": "OYwc41lVKk29"
   },
   "source": [
    "<div dir=rtl>\n",
    "\n",
    "در سلول بالا فرآیند آموزش را به گونه ای تغییر داده ایم که متناسب با نیاز wandb باشد و بتواند برای حالاتی که از اون میخواهیم مدلهای گوناگون و مناسبی آموزش دهد.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799d5672",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "799d5672",
    "outputId": "f5d84acd-7d92-4319-a8b1-9ca56cfe2b7e"
   },
   "outputs": [],
   "source": [
    "!pip install wandb -Uq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f307b661",
   "metadata": {
    "id": "f307b661"
   },
   "outputs": [],
   "source": [
    "# !pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ad2cc9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "56ad2cc9",
    "outputId": "78449dad-216f-4b33-aaf3-aa22776826a8"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17f827e",
   "metadata": {
    "id": "e17f827e"
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'random'\n",
    "    }\n",
    "metric = {\n",
    "    'name': 'loss',\n",
    "    'goal': 'minimize'   \n",
    "    }\n",
    "\n",
    "sweep_config['metric'] = metric\n",
    "\n",
    "parameters_dict = {\n",
    "    'optimizer': {\n",
    "        'values': ['adam', 'sgd']\n",
    "        },\n",
    "    'dropout': {\n",
    "          'values': [0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "        },\n",
    "    'batch_normalization': {\n",
    "            'values': [True, False]\n",
    "        }\n",
    "    }\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict\n",
    "\n",
    "parameters_dict.update({\n",
    "    'epochs': {\n",
    "        'values': [1, 3 , 5, 7]}\n",
    "    })\n",
    "\n",
    "\n",
    "parameters_dict.update({\n",
    "    'learning_rate': {\n",
    "        # a flat distribution between 0 and 0.1\n",
    "        'distribution': 'uniform',\n",
    "        'min': 0,\n",
    "        'max': 0.1\n",
    "      },\n",
    "    'batch_size': {\n",
    "        # integers between 32 and 256\n",
    "        # with evenly-distributed logarithms \n",
    "        'distribution': 'q_log_uniform_values',\n",
    "        'q': 8,\n",
    "        'min': 32,\n",
    "        'max': 256,\n",
    "      }\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4QsgTq_7K9cB",
   "metadata": {
    "id": "4QsgTq_7K9cB"
   },
   "source": [
    "<div dir=rtl>\n",
    "\n",
    "در سلول بالا تنظیمات گوناگونی که من میخواهم بهترین حالات از بین آنها انتخاب شود را مشخص کرده ام.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a904a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6a904a1",
    "outputId": "1c4939bd-9afd-4dfc-bade-9a46ca02b935"
   },
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"pytorch_sweeps_HW2_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b80afa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "99e2a9fc096d4119b2dd9ee83ce219ae",
      "aa699d223b4e44899bb2ec34207bb40a",
      "fdde52337f63468aa2fcd1d97e0fa2e8",
      "c7f47e8b41724da7aae9892692b4c230",
      "0a7f2705b8ba41b7abdec41a85de07da",
      "e8d62f3b0a054b76865b19eebf14da35",
      "d310bf699a80463783971ac3a3b7d573",
      "2600ea1aafa3493da2b3fd2b5051ae2d",
      "2fe2dd653cb34155acff5d057e57a1fa",
      "ee2c069ca00349eb9c0dd72dd025bf0a",
      "cc2dab347a834ba1ab3af24df5a35794",
      "6810435c88da4de586fa04930eec655c",
      "f88a2507a9704999a511291438cd7502",
      "bc65cf6ac9c24bb0a6e646c7fab48cbc",
      "4a9ecf5bc9fd427a8d5b003bb56ca161",
      "5c306e80ce214e83bbe76a86a8d44db3",
      "2a0816fc86b6469faa3b24c7c1a4a4aa",
      "eeb0e89c2257485aaecc6d06f6bc7f61",
      "e3186b373ad24f4996dd21c967dfdcc2",
      "6ac4362fab2740f69c50bbd279ee53f7",
      "e69ec4dd8cd940df9a1f52afb51eedfb",
      "d62f73e954794457afc0fcf96c3fbf92",
      "5d71a2cbc8a844b6889afeafa532b791",
      "e71befd79e644a55a36c1e3d9dce7b24",
      "b4a9297c377744cd835764f140614df3",
      "945d57402b204a39be49632105c09d63",
      "53a4dc1ef97e4229a26ea65d1613d787",
      "cd9e2df478ff45968be20bd147365af8",
      "5ec803b3e70c4c969dd29eb52969ad91",
      "1858861bb9c64df28949e51b62b25732",
      "b6fe256f3541444599b975dc583fb080",
      "ca88e268dd0f4e7ab873523f2a90d837"
     ]
    },
    "id": "e0b80afa",
    "outputId": "c981fe9a-edde-464c-a500-36d6695638a7"
   },
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, train, count=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DyA4eEg2LIE6",
   "metadata": {
    "id": "DyA4eEg2LIE6"
   },
   "source": [
    "<div dir=rtl>\n",
    "\n",
    "در سلول بالا با استفاده از ماژول wandb برای کانفیگ مشخص شده فرآیند آموزش متوالی مدل انجام شده است.\n",
    "\n",
    "نتیجه ی اجرای این سلول را میتوانید در لینک زیر مشاهده نمایید:\n",
    "\n",
    "https://wandb.ai/farkoo/pytorch_sweeps_HW2_5/sweeps/lxhy9tdi?workspace=user-farzanehkoohestani1999\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FYm8RI40MpGw",
   "metadata": {
    "id": "FYm8RI40MpGw"
   },
   "source": [
    "<div dir=rtl>\n",
    "\n",
    "همانطور که در لینک بالا قابل مشاهده است در این بخش بهترین تنظمیات شبکه که این ابزار مشخص کرده است را گزارش میدهم:\n",
    "\n",
    "</div>\n",
    "\n",
    "* Batch Normalization: True\n",
    "* Batch Size: 5\n",
    "* Dropout: 0.2\n",
    "* Epochs: 3\n",
    "* Learning Rate: 0.008\n",
    "* Optimizer: SGD\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MBMfEv5ZPWcL",
   "metadata": {
    "id": "MBMfEv5ZPWcL"
   },
   "source": [
    "# سوال 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016186d7",
   "metadata": {
    "id": "016186d7"
   },
   "outputs": [],
   "source": [
    "def classify(model, image_transforms, image):\n",
    "  model = model.eval()\n",
    "  image = image_transforms(image).float()\n",
    "  image = image.to(device)\n",
    "  image = image.unsqueeze(0)\n",
    "  \n",
    "  output = model(image)\n",
    "  _, predicted = torch.max(output[0], 1)\n",
    "\n",
    "  return predicted.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oelZzbs9aFpU",
   "metadata": {
    "id": "oelZzbs9aFpU"
   },
   "source": [
    "<div dir=rtl>\n",
    "\n",
    "در این تابع با دریافت مدل، تبدیل کننده ی تصویر و خود تصویر، خروجی اجرای مدل روی تصویر به دست آمده و برگردانده میشود.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9da4a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2e9da4a9",
    "outputId": "5e69e1b7-42ce-486b-a77e-807ad1133127"
   },
   "outputs": [],
   "source": [
    "MAIN = '/content/drive/MyDrive/_test_'\n",
    "cascPath = '/content/drive/MyDrive/haarcascade_frontalface_default.xml'\n",
    "label = [0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1]\n",
    "mask_dict = {\n",
    "  0: \"With Mask\",\n",
    "  1: \"Without Mask\",\n",
    "}\n",
    "acc = 0\n",
    "for i in range(1, 21):\n",
    "  imagePath = os.path.join(MAIN, str(i) + '.jpeg')\n",
    "  faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "  image = Image.open(imagePath)\n",
    "\n",
    "  # Detect faces in the image\n",
    "  faces = faceCascade.detectMultiScale(\n",
    "      np.array(image),\n",
    "      scaleFactor=1.1,\n",
    "      minNeighbors=5,\n",
    "      minSize=(30, 30),\n",
    "      flags = cv2.CASCADE_SCALE_IMAGE\n",
    "  )\n",
    "  for (x, y, w, h) in faces:\n",
    "    face = image.crop((x, y, x+w, y+h))\n",
    "  predicted = classify(model_sgd_dropout_batch, transform, face)\n",
    "  display(face)\n",
    "  print('Predicted:', mask_dict[predicted], '    *****    ', 'Actual:', mask_dict[label[i-1]])\n",
    "  if predicted == label[i-1]:\n",
    "        acc += 1\n",
    "acc = acc/20\n",
    "print('\\n \\n ------------------------------------ \\n Test Accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IzNtBmr_akDR",
   "metadata": {
    "id": "IzNtBmr_akDR"
   },
   "source": [
    "<div dir=rtl>\n",
    "\n",
    "در این قسمت 20 تصویر، که 10 تای آن با ماسک و 10 تای آن بدون ماسک است استفاده شده است.\n",
    "\n",
    "تک به تک این تصاویر خوانده شده اند و با استفاده از کد آماده ای در opencv ناحیه ی صورت تشخیص داده و برش شده است.\n",
    "\n",
    "سپس این تصویر برش داده شده به تابع Classify که قبلا به آن پرداختیم به همراه تبدیل transform که ابعاد تصویر را به 32 در 32 تبدیل میکرد به همراه بهترین مدلی که تا کنون آموزش داده ایم یعنی model_sgd_dropout_batch داده شده است.\n",
    "\n",
    "سپس تصویر برش داده شده، مقدار پیش بینی شده برای کلاس آن و کلاس واقعی تصویر را نمایش میدهد.\n",
    "\n",
    ".\n",
    "\n",
    "برای تک تک تصاویر این مراحل طی میشود و دقت مدل روی این 20 تصویر محاسبه و نمایش داده میشود.\n",
    "\n",
    "مدل ما 19 تصویر از 20 تصویر را درست دسته بندی کرده است و دقت نهایی آن برابر با 95 درصد بدست آمده است.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RYCJI7TKSImj",
   "metadata": {
    "id": "RYCJI7TKSImj"
   },
   "source": [
    "# سوال 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aue1v6XJb5Qr",
   "metadata": {
    "id": "aue1v6XJb5Qr"
   },
   "source": [
    "<div dir=rtl>\n",
    "\n",
    "در این قسمت از مدل resnet50 برای بهره گیری از یادگیری انتقالی استفاده میکنیم.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f42f4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "3a6c9dbc34b24fa0a93ddc4b37024bce",
      "e39ae5b816bd4c7c9afd035381b0710b",
      "37d3714015f24e6baa77a9b17884a5ee",
      "9da38028549246e6b89a0b6ab4d01f32",
      "ef1016c2314f4c9da0747a1e307332de",
      "341b0886dd8b495a9eb2a7d80d2c0f4e",
      "1ac1f4334f1c4e34b9236e55012390b5",
      "0193eee081f64dc1b71f413d31d2ab6d",
      "7db167ee40b740708893053dc153d6b8",
      "38e7a1c0db144378b444d01ed5b4bc2b",
      "0afeef3f2954498581adad9e2b6c281a"
     ]
    },
    "id": "85f42f4f",
    "outputId": "84e03abc-6950-468a-9520-16f80d7eaa8a"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = False\n",
    "num_features = model.fc.in_features     #extract fc layers features\n",
    "model.fc = nn.Linear(num_features, 2) #(num_of_class == 2)\n",
    "model = model.to(device) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3vHuVi3GcK1L",
   "metadata": {
    "id": "3vHuVi3GcK1L"
   },
   "source": [
    "<div dir=rtl>\n",
    "\n",
    "در سلول بالا مدل resnet50 دانلود میشود سپس،\n",
    "\n",
    "سپس با flase کردن param.requires_grad مشخص میکنیم که قصد نداریم لایه های درونی مدل آموزش ببیند و از وزنهایی که قبلا بدست آمده است میخواهیم استفاده کنیم.\n",
    "\n",
    "سپس با اضافه کردن یک لایه Linear خروجی آخرین لایه را به تعداد کلاسهایمان یعنی 2 کاهش میدهیم.\n",
    "\n",
    "مدل resnet50 برای آموزش آماده است.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fc82b9",
   "metadata": {
    "id": "22fc82b9"
   },
   "outputs": [],
   "source": [
    "def train_(model, iterator, optimizer, criterion, device):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_prec = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "    for (x, y) in tqdm(iterator, desc=\"Training\", leave=False):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        _, y_pred = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        acc = metrics.accuracy_score(y_pred.cpu().numpy(), y.cpu().numpy())#calculate_accuracy(y_pred, y)\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6F7RRaGmdAoL",
   "metadata": {
    "id": "6F7RRaGmdAoL"
   },
   "source": [
    "<div dir=rtl>\n",
    "\n",
    "از این تابع برای آموزش مدل pretrain شده استفاده میکنیم.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98d0c09",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "f98d0c09",
    "outputId": "cd1a2435-cd76-4c24-8985-0b782ebaaea0"
   },
   "outputs": [],
   "source": [
    "model_resnet50 = model\n",
    "OUTPUT_DIM = 2\n",
    "FOUND_LR = 1e-3\n",
    "EPOCHS=5\n",
    "optimizer = optim.SGD(model_resnet50.parameters(), lr=FOUND_LR, momentum=0.9)\n",
    "\n",
    "loss = []\n",
    "acc = []\n",
    "epochs = []\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in trange(EPOCHS, desc=\"Epochs\"):\n",
    "\n",
    "    start_time = time.monotonic()\n",
    "    train_loss, train_acc = train_(model_resnet50, train_set.dataset, optimizer, criterion, device)\n",
    "    loss.append(train_loss)\n",
    "    acc.append(train_acc)\n",
    "    epochs.append(epoch)\n",
    "    \n",
    "    torch.save(model_resnet50.state_dict(), 'model_resnet50.pt')\n",
    "\n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "\n",
    "plt.plot(epochs, loss)\n",
    "plt.plot(epochs, acc)\n",
    "plt.plot(epochs, loss, 'g', label='Training loss')\n",
    "plt.plot(epochs, acc, 'r', label='validation loss')\n",
    "plt.title('Training loss and Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss and Acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ipru7E1ndMSN",
   "metadata": {
    "id": "Ipru7E1ndMSN"
   },
   "source": [
    "<div dir=rtl>\n",
    "\n",
    "در سلول بالا مدل pretrain شده ی resnet50 را آموزش داده ایم.\n",
    "\n",
    "برای آموزش این مدل از تابع بهینه سازی SGD استفاده کرده ام،\n",
    "\n",
    "فرآیند آموزش برای 5 ایپاک انجام شده است،\n",
    "\n",
    "از تابع CrossEntropyLoss برای محاسبه loss مدل استفاده شده است،\n",
    "\n",
    "نهایتا مدل، دیتالودر آموزش، optimizer و تابع محاسبه loss به تابع train داده شده است و این فرآیند به تعداد ایپاکها یعنی 5 بار تکرار شده است.\n",
    "\n",
    "در پایان هر ایپاک مقدار loss و accuracy محاسبه شده اند و نمایش داده میشوند.\n",
    "\n",
    "نهایتا همانطور که خواسته شده نمودار مقدار loss و accuracy فرآیند آموزش نمایش داده میشود.\n",
    "\n",
    ".\n",
    "\n",
    "نهایتا مشاهده میکنیم دقت آموزش برای این مدل برابر با 80 درصد میشود.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "riAyD1RQX6Wf",
   "metadata": {
    "id": "riAyD1RQX6Wf"
   },
   "outputs": [],
   "source": [
    "def classify_(model, image_transforms, image):\n",
    "  model = model.eval()\n",
    "  image = image_transforms(image).float()\n",
    "  image = image.to(device)\n",
    "  image = image.unsqueeze(0)\n",
    "  output = model(image)\n",
    "  _, predicted = torch.max(output, 1)\n",
    "  return predicted.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZIb524gFViEt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZIb524gFViEt",
    "outputId": "aba34270-1dbd-45fa-cc41-e4de852de335"
   },
   "outputs": [],
   "source": [
    "MAIN = '/content/drive/MyDrive/_test_'\n",
    "cascPath = '/content/drive/MyDrive/haarcascade_frontalface_default.xml'\n",
    "label = [0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1]\n",
    "mask_dict = {\n",
    "  0: \"With Mask\",\n",
    "  1: \"Without Mask\",\n",
    "}\n",
    "acc = 0\n",
    "for i in range(1, 21):\n",
    "  imagePath = os.path.join(MAIN, str(i) + '.jpeg')\n",
    "  faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "  image = Image.open(imagePath)\n",
    "\n",
    "  # Detect faces in the image\n",
    "  faces = faceCascade.detectMultiScale(\n",
    "      np.array(image),\n",
    "      scaleFactor=1.1,\n",
    "      minNeighbors=5,\n",
    "      minSize=(30, 30),\n",
    "      flags = cv2.CASCADE_SCALE_IMAGE\n",
    "  )\n",
    "  for (x, y, w, h) in faces:\n",
    "    face = image.crop((x, y, x+w, y+h))\n",
    "  predicted = classify_(model_resnet50, transform, face)\n",
    "  display(face)\n",
    "  print('Predicted:', mask_dict[predicted], '    *****    ', 'Actual:', mask_dict[label[i-1]])\n",
    "  if predicted == label[i-1]:\n",
    "        acc += 1\n",
    "acc = acc/20\n",
    "print('\\n \\n ------------------------------------ \\n Test Accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ovnnEGiPdsN6",
   "metadata": {
    "id": "ovnnEGiPdsN6"
   },
   "source": [
    "<div dir=rtl>\n",
    "\n",
    "در این قسمت 20 تصویر، که 10 تای آن با ماسک و 10 تای آن بدون ماسک است استفاده شده است.\n",
    "\n",
    "تک به تک این تصاویر خوانده شده اند و با استفاده از کد آماده ای در opencv ناحیه ی صورت تشخیص داده و برش شده است.\n",
    "\n",
    "سپس این تصویر برش داده شده به تابع Classify که قبلا به آن پرداختیم به همراه تبدیل transform که ابعاد تصویر را به 32 در 32 تبدیل میکرد به همراه مدل resnet50 داده شده است.\n",
    "\n",
    "سپس تصویر برش داده شده، مقدار پیش بینی شده برای کلاس آن و کلاس واقعی تصویر را نمایش میدهد.\n",
    "\n",
    ".\n",
    "\n",
    "برای تک تک تصاویر این مراحل طی میشود و دقت مدل روی این 20 تصویر محاسبه و نمایش داده میشود.\n",
    "\n",
    "مدل resnet50 سیزده تصویر از 20 تصویر را درست دسته بندی کرده است و دقت نهایی آن برابر با 65 درصد بدست آمده است.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uBqt_JrMZz8O",
   "metadata": {
    "id": "uBqt_JrMZz8O"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0193eee081f64dc1b71f413d31d2ab6d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a7f2705b8ba41b7abdec41a85de07da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0afeef3f2954498581adad9e2b6c281a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1858861bb9c64df28949e51b62b25732": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ac1f4334f1c4e34b9236e55012390b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2600ea1aafa3493da2b3fd2b5051ae2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2a0816fc86b6469faa3b24c7c1a4a4aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eeb0e89c2257485aaecc6d06f6bc7f61",
       "IPY_MODEL_e3186b373ad24f4996dd21c967dfdcc2"
      ],
      "layout": "IPY_MODEL_6ac4362fab2740f69c50bbd279ee53f7"
     }
    },
    "2fe2dd653cb34155acff5d057e57a1fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ee2c069ca00349eb9c0dd72dd025bf0a",
       "IPY_MODEL_cc2dab347a834ba1ab3af24df5a35794"
      ],
      "layout": "IPY_MODEL_6810435c88da4de586fa04930eec655c"
     }
    },
    "341b0886dd8b495a9eb2a7d80d2c0f4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37d3714015f24e6baa77a9b17884a5ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0193eee081f64dc1b71f413d31d2ab6d",
      "max": 102530333,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7db167ee40b740708893053dc153d6b8",
      "value": 102530333
     }
    },
    "38e7a1c0db144378b444d01ed5b4bc2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a6c9dbc34b24fa0a93ddc4b37024bce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e39ae5b816bd4c7c9afd035381b0710b",
       "IPY_MODEL_37d3714015f24e6baa77a9b17884a5ee",
       "IPY_MODEL_9da38028549246e6b89a0b6ab4d01f32"
      ],
      "layout": "IPY_MODEL_ef1016c2314f4c9da0747a1e307332de"
     }
    },
    "4a9ecf5bc9fd427a8d5b003bb56ca161": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53a4dc1ef97e4229a26ea65d1613d787": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6fe256f3541444599b975dc583fb080",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ca88e268dd0f4e7ab873523f2a90d837",
      "value": 1
     }
    },
    "5c306e80ce214e83bbe76a86a8d44db3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5d71a2cbc8a844b6889afeafa532b791": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ec803b3e70c4c969dd29eb52969ad91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6810435c88da4de586fa04930eec655c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ac4362fab2740f69c50bbd279ee53f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7db167ee40b740708893053dc153d6b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "945d57402b204a39be49632105c09d63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ec803b3e70c4c969dd29eb52969ad91",
      "placeholder": "​",
      "style": "IPY_MODEL_1858861bb9c64df28949e51b62b25732",
      "value": "0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "99e2a9fc096d4119b2dd9ee83ce219ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aa699d223b4e44899bb2ec34207bb40a",
       "IPY_MODEL_fdde52337f63468aa2fcd1d97e0fa2e8"
      ],
      "layout": "IPY_MODEL_c7f47e8b41724da7aae9892692b4c230"
     }
    },
    "9da38028549246e6b89a0b6ab4d01f32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_38e7a1c0db144378b444d01ed5b4bc2b",
      "placeholder": "​",
      "style": "IPY_MODEL_0afeef3f2954498581adad9e2b6c281a",
      "value": " 97.8M/97.8M [00:01&lt;00:00, 106MB/s]"
     }
    },
    "aa699d223b4e44899bb2ec34207bb40a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a7f2705b8ba41b7abdec41a85de07da",
      "placeholder": "​",
      "style": "IPY_MODEL_e8d62f3b0a054b76865b19eebf14da35",
      "value": "0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "b4a9297c377744cd835764f140614df3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_945d57402b204a39be49632105c09d63",
       "IPY_MODEL_53a4dc1ef97e4229a26ea65d1613d787"
      ],
      "layout": "IPY_MODEL_cd9e2df478ff45968be20bd147365af8"
     }
    },
    "b6fe256f3541444599b975dc583fb080": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc65cf6ac9c24bb0a6e646c7fab48cbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c7f47e8b41724da7aae9892692b4c230": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca88e268dd0f4e7ab873523f2a90d837": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cc2dab347a834ba1ab3af24df5a35794": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a9ecf5bc9fd427a8d5b003bb56ca161",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5c306e80ce214e83bbe76a86a8d44db3",
      "value": 1
     }
    },
    "cd9e2df478ff45968be20bd147365af8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d310bf699a80463783971ac3a3b7d573": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d62f73e954794457afc0fcf96c3fbf92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e3186b373ad24f4996dd21c967dfdcc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d71a2cbc8a844b6889afeafa532b791",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e71befd79e644a55a36c1e3d9dce7b24",
      "value": 1
     }
    },
    "e39ae5b816bd4c7c9afd035381b0710b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_341b0886dd8b495a9eb2a7d80d2c0f4e",
      "placeholder": "​",
      "style": "IPY_MODEL_1ac1f4334f1c4e34b9236e55012390b5",
      "value": "100%"
     }
    },
    "e69ec4dd8cd940df9a1f52afb51eedfb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e71befd79e644a55a36c1e3d9dce7b24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e8d62f3b0a054b76865b19eebf14da35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee2c069ca00349eb9c0dd72dd025bf0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f88a2507a9704999a511291438cd7502",
      "placeholder": "​",
      "style": "IPY_MODEL_bc65cf6ac9c24bb0a6e646c7fab48cbc",
      "value": "0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "eeb0e89c2257485aaecc6d06f6bc7f61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e69ec4dd8cd940df9a1f52afb51eedfb",
      "placeholder": "​",
      "style": "IPY_MODEL_d62f73e954794457afc0fcf96c3fbf92",
      "value": "0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "ef1016c2314f4c9da0747a1e307332de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f88a2507a9704999a511291438cd7502": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fdde52337f63468aa2fcd1d97e0fa2e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d310bf699a80463783971ac3a3b7d573",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2600ea1aafa3493da2b3fd2b5051ae2d",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
